---
title: "Supply Chain Analytics IA#1 - Rajshree Mishra (rm62528)"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

------------------------------------------------------------------------

<center>
## Individual Assignment #1: ETS Laboratory
#### Due: Nov. 3 (Before Class)
#### (40 points)
</center>

------------------------------------------------------------------------

You have been hired by a company in the hospitality business to help
them plan the staffing levels for the following year. The company
operates resorts in three regions of the New South Wales of Australia;
the three regions are the **Sydney**, the **South Coast** and the
**North Coast NSW** areas.

As it takes time to hire new personnel and it is necessary for any new
employee to undergo a detailed training program before starting to work,
the company needs to plan its personnel requirements one year in
advance. Furthermore, as it is possible for the company to transfer
qualified personnel between regions, they are interested only in an
aggregate forecast of their demand

As the company caters to **Holiday** travelers, and it has been growing
faster than the market (i.e., it has been gaining market share), the
Chief Commercial Officer estimates that next year they will have
respectively (3%, 4%, 4%) of only the **Holiday** travelers in the
(**Sydney**, **South Coast**, and **North Coast NSW**) regions
respectively. Furthermore based on prior experience they anticipate that
each traveler will stay respectively (5,2,2) hotel-nights in
(**Sydney**, **South Coast**, and **North Coast NSW**) respectively

To forecast demand in hotel-nights use the **tourism** data set in
**fpp3**. This data set reports the quarterly trips (in thousands) to
different destinations, and as this data set has a *tsibble* structure,
you can use **tidyverse** functions to subset the time-series of
interest.

For the purposes of this assignment ignore all data before **2008 Q1**
and use the data from **2008 Q1** through **2016 Q4** as a training set
and the four quarters of **2017** as a testing set.

If you need to dust-off the tidyverse functions, a good reference is the
electronic book [*R for Data Science*](https://r4ds.had.co.nz/) or
alternatively, if you only need a quick refresher of the **dplyr** and
**tidyr** functions you can use the following [*Data Wrangling Cheat
Sheet*](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

### Part I. Model-Aggregation Forecast

#### 1. After sub-setting for the time-series of interest in the **tourism** data set (a *tsibble*), add to the restricted set the corresponding demand time-series, by creating a column called *Demand* for each of the corresponding regions of interest. The *Demand* column should contain the hotel-nights (in thousands) corresponding to each of the *Trips* observations. After creating the *Demand* column, the code below uses the **group_by()** function to aggregate demand across regions creating the *AGG.D* column with the total demand and you are asked to find the best **ETS** model for each *Demand* time-series. In addition to the automatic fit, one of your colleagues suggest that you should find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend, as the automatic selection is based only on the AICc criterion, and the models with trend may be better under the *BIC* criterion. Report the best model as well as the corresponding *AICc* and *BIC*. What is the best model according to the information criteria?

```{r}
library(fpp3)

# Subset the appropriate data and create the "Demand" time-series
tourism %>% 
  filter(Quarter >= yearquarter("2008 Q1")) %>%
  filter(Purpose == "Holiday" & State == "New South Wales") %>%
  filter(Region %in% c("North Coast NSW","South Coast","Sydney")) %>%
  mutate(Demand = case_when(
    Region == "Sydney" ~ 0.03*Trips*5,
    Region == "South Coast" ~ 0.04*Trips*2,
    Region == "North Coast NSW" ~ 0.04*Trips*2
  )) -> D

D %>%
  group_by() %>%
  summarize(AGG.D = sum(Demand)) -> AD


# Break into Training and Testing sets.

ADTR <- AD %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
ADTE <- AD %>% 
  filter(Quarter >= yearquarter("2017 Q1"))

# Solution

m_c <- ADTR %>%  
  model(m.auto = ETS(AGG.D),
        m.ZAZ = ETS(AGG.D ~ trend("A")),
        m.ZAdZ = ETS(AGG.D ~ trend("Ad")))

m_c %>% glance() 

```

Solution:

According to the reports generated by each model, the ETS-automatically 
chosen "ANA" model is the best one. Its AIC and BIC values are lower than
those of other models. These are the numbers: AIC 306.8655 AICc
310.8655 BIC 317.9501

In addition to automatic selection using additive trend, the optimum model is
'AAA'. In addition to automatic selection with for additive-damped trend,
the best model is "AAdA."

#### 2. Now calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the three models fitted in (1). 

Solution:

For each of the three models, the in-sample (training) and out-of-sample (testing) metrics::

```{r}
fore_c <- m_c %>% forecast(h=4) #only next 4 months data available
rbind(m_c %>% accuracy(), fore_c %>% accuracy(data = ADTE))
```

#### 3. Using the model with the lowest out-of-sample *MAPE*, and using all data (i.e., the *AD* dataset) prepare a forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence intervals. 

Solution: The out-of-sample MAPE with the lowest value is "ETS(AGG.D trend("A")" and the four quarters of 2018 will be forecasted using this model.


```{r}
m_ad <- AD %>%  model(low_mape_ad_model = ETS(AGG.D ~ trend("A")))
fc_2018<- m_ad %>% forecast(h=4)
fc_2018
```

The point forecasts as well as the 80% and 95% confidence intervals:


```{r}
# obtaining two-sided confidence intervals of 80% and 95% for the forecast
fc_2018 %>% hilo(level =c(80,95))%>%unpack_hilo("80%")%>%unpack_hilo("95%")
```

#### 4. As in the hospitality business it is very costly to be short of personnel and your brand gets degraded when demand exceeds staffing capacity, we need to plan the staffing levels for each quarter according to a forecast of demand that we anticipate it will not be exceeded with a probability of 99%. What are these four quarterly demand levels?

Solution:


The four quarterly demand levels are:


```{r}
fc_2018 %>% mutate(Q99 = quantile(AGG.D, 0.99))  -> gn_2018
gn_2018
```

### Part II. Infrastructure Capacity Planning Forecast

Because resort infrastructure (such as buildings) and direct
fixed costs cannot be transferred between regions, it is crucial
that we carefully consider the capacities we should create in each
one. To do this, we must first forecast demand separately for each
location, then quantify the expected levels of occupation and the 
operational risk on the downside for each region.

#### 5. Use the region-specific training and testing data (see code box below) and automatically select the ETS model that minimizes AICc, and as your colleague suggested also find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend as they may be preferred under the BIC criterion. Your mable should have 9 models in all; three models for each of the three regions. Report for each of the three models the corresponding AICc and BIC for each region. What is the ETS-name of the best model for each region according to the AICc information criterion? What is the best model for each region according to the BIC information criterion? 

Solution: 

Mable having 9 models:



```{r}
# Break Region-Specific data into Training and Testing sets.
DTR <- D %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
DTE <- D %>% 
  filter(Quarter >= yearquarter("2017 Q1"))

m_c_2 <- DTR %>%  
  model(m.auto_2 = ETS(Demand), m.ZAZ_2 = ETS(Demand ~ trend("A")),
        m.ZAdZ_2 = ETS(Demand ~ trend("Ad")))

m_c_2 %>% glance() 
```

The best model, as determined by the AICc information criteria, has the ETS-name
1. North Coast NSW is ETS (M,N,M) 2. South Coast is ETS (M,N,M) Sydney is ETS 3. (A,N,A)

The best model, as determined by the BIC information criteria, has the ETS-name
1. North Coast NSW is ETS (M,N,M) 2. South Coast is ETS (M,N,M) Sydney is ETS 3. (A,N,A)

#### 6. Calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the nine models fitted in (5). Sometimes the damped models can introduce a bias in forecasting horizons longer than one or two periods. Is this a concern for the "Ad"model for any of the three regions? Explain. Using for each region the model with the lowest BIC, and using all data (i.e., the D dataset) prepare a region-specific forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence intervals.

Solution:

The in-sample (training) and the out-of-sample (testing) metrics for
each of the nine models fitted in (5):

```{r}
fore_c_2 <- m_c_2 %>% forecast(h=4) 
rbind(m_c_2 %>% accuracy(), fore_c_2 %>% accuracy(data = DTE))
```

The graphs below show a clear indication of the 'AAdM' model's
slight bias. South coast bias is nearly nonexistent, North coast
bias is very low, and Sydney bias is very significant.

The bias starts to show after the second period.

```{r}
f_r = m_c_2 %>%  augment() 

f_r %>% autoplot(.vars = Demand, col = "black") + 
  geom_point(data = f_r, mapping = aes(y = .fitted))

fc_r = m_c_2 %>% forecast(h = 4)

fc_r %>% autoplot(DTR) +
          geom_point(data = f_r, mapping = aes(y = .fitted), col = "red") +
          geom_point(data = DTE, mapping = aes(y = Demand), col = "green")
```

We know that ETS-name of the best model according to BIC information
criterion is 1. North Coast NSW is ETS(M,N,M) 2. South Coast is
ETS(M,N,M) 3. Sydney is ETS(A,N,A)

```{r}
D_NSW <- D %>% filter(Region == "North Coast NSW") %>%  model(ETS(Demand ~ error("M") + trend("N") + season("M")))

f_NSW_2018<- D_NSW %>% forecast(h=4)
f_NSW_2018%>% hilo(level =c(80,95)) %>% unpack_hilo("80%") %>% unpack_hilo("95%")
```

```{r}
D_SC <- D %>% filter(Region == "South Coast") %>%  model(ETS(Demand ~ error("M") + trend("N") + season("M")))

f_SC_2018<- D_SC %>% forecast(h=4)
f_SC_2018%>% hilo(level =c(80,95)) %>% unpack_hilo("80%") %>% unpack_hilo("95%")
```

```{r}
D_SYD <- D %>% filter(Region == "Sydney") %>%  model(ETS(Demand ~ error("A") + trend("N") + season("A")))

f_SYD_2018<- D_SYD %>% forecast(h=4)

f_SYD_2018%>% hilo(level =c(80,95)) %>% unpack_hilo("80%") %>% unpack_hilo("95%")
```

#### 7. As infrastructure (buildings, etc) cannot be modified from quarter to quarter, we must plan for capacity level for the entire year in each of the three regions. As with personnel, management thinks it is too expensive to be out of capacity to satisfy demand, and have proposed to build enough capacity to satisfy all demand of the highest season with a probability of 98%. What is the constant quarterly capacity that they should build in each region? If we define the mean-forecast occupancy rate as the occupancy rate implied by the mean forecast, prepare a table showing the mean-forecast occupancy rate for each of the four quarters at each of the three regions.

Solution:

The capacity to meet all demand during the peak season in each
region with a probability of 98% is found, and this capacity is
used to compute the constant quarterly capacity.:

```{r}
f_NSW_2018 %>% mutate(Q98 = quantile(Demand, 0.98))  -> g_NSW_2018
cat('The constant quarterly capacity that they should build in North Coast NSW region :: ')
constant_Q_capacity_NSW=max(g_NSW_2018$Q98)
constant_Q_capacity_NSW

```

```{r}
f_SC_2018 %>% mutate(Q98 = quantile(Demand, 0.98))  -> g_SC_2018
cat('The constant quarterly capacity that they should build in South Coast region :: ')
constant_Q_capacity_SC=max(g_SC_2018$Q98)
constant_Q_capacity_SC
```

```{r}
f_SYD_2018 %>% mutate(Q98 = quantile(Demand, 0.98))  -> g_SYD_2018
cat('The constant quarterly capacity that they should build in Sydney region :: ')
constant_Q_capacity_SYD=max(g_SYD_2018$Q98)
constant_Q_capacity_SYD
```

Below is a list of each region's mean-forecast occupancy rate,
which is the occupancy rate implied by the mean forecast:

```{r}
g_NSW_2018$ constant_Q_capacity = constant_Q_capacity_NSW
g_SC_2018$ constant_Q_capacity = constant_Q_capacity_SC
g_SYD_2018$ constant_Q_capacity = constant_Q_capacity_SYD

consolidated_fore_c <- rbind(g_NSW_2018,g_SC_2018,g_SYD_2018) %>% as_tibble
consolidated_fore_c$mean_fc_occupancy = consolidated_fore_c$`.mean`/consolidated_fore_c$constant_Q_capacity

consolidated_fore_c %>% select(Region,Quarter,`.mean`,constant_Q_capacity,mean_fc_occupancy)
```

#### 8. Another metric of interest is the 10%-down-side occupancy risk. This will be measured as the occupancy rate that would be obtained if actual demand is at the low 10% of the probability distribution of its forecast. What is the 10% level of the forecast probability distribution for each quarter at each region. Prepare also a table showing the 10%-downside-occupancy for each quarter at each region.

Solution:

The occupancy rate for each quarter in each region and the 10%
level of the predicted probability distribution:

```{r}

consolidated_fore_c %>% mutate(Q10 = quantile(Demand, 0.10)) %>% select(Region, Quarter, constant_Q_capacity, Q10)  %>% mutate(occupancy_rate = Q10/constant_Q_capacity)

```
